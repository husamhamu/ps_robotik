
---

# Projektseminar an TU Darmstadt  
## Zusammenfassung:  
Ziel dieser Arbeit ist die Entwicklung eines KI-gesteuerten Fahrzeugs, **JetBot AI**, unter Nutzung des NVIDIA Jetson Nano Moduls. Der Fokus liegt auf der Implementierung zentraler FunktionalitÃ¤ten wie der autonomen Hinderniserkennung mittels Kameradaten, der Planung von Navigationspfaden sowie der Bewegungssteuerung des Fahrzeugs. Durch die Analyse von Umgebungsdaten wird ein sicherer Navigationspfad generiert, um Hindernisse effektiv zu vermeiden, und der JetBot wird prÃ¤zise gesteuert, um die erforderlichen Aktionen auszufÃ¼hren. Die Arbeit integriert fortschrittliche Methoden wie Kartenerstellung, Hinderniserkennung und Umgehungsalgorithmen. Es werden die eingesetzten Verfahren zur Objekterkennung, Hindernisvermeidung und Pfadplanung detailliert erlÃ¤utert, einschlieÃŸlich Mapping, Objektverfolgung und -sortierung.

---

# ğŸš— JetBot: KI-gesteuerter autonomer Roboter auf dem NVIDIA Jetson Nano

![JetBot Demo](https://github.com/husamhamu/ps_robotik/assets/demo.gif) <!-- Ersetze durch echten GIF- oder Video-Link -->

> **JetBot** ist ein KI-basierter autonomer Roboter auf Basis des NVIDIA Jetson Nano. Er bietet Objekterkennung durch Deep Learning, Hindernis-Lokalisierung mittels AprilTags, Echtzeit-Pfadplanung sowie autonome Navigation durch RRT-Algorithmen und PID-Motorsteuerung.

## ğŸ§  Zentrale Funktionen

- ğŸ” **Objekterkennung**: Integration und Benchmarking von SSD, YOLOv7 und YOLOv3 fÃ¼r Echtzeit-Objekterkennung auf eingebetteter Hardware.  
- ğŸ§­ **Navigation & Hindernisvermeidung**: Lokalisierung von Hindernissen mittels Kamerakalibrierung und AprilTag-Erkennung sowie deren Umgehung durch fortgeschrittene Koordinatentransformationen und Bewegungsplanung.  
- ğŸ—ºï¸ **Pfadplanung**: Implementierung der Algorithmen RRT und RRT* (Rapidly-exploring Random Tree) zur dynamischen Pfadsuche in einer komplexen Umgebung.  
- ğŸ¤– **Robotersteuerung**: Einsatz eines PID-Reglers zur Steuerung des Motorverhaltens basierend auf Kameradaten und Objektposition.  
- ğŸ“¡ **ROS-Integration**: VollstÃ¤ndig integriert in das Robot Operating System (ROS) zur Verarbeitung und Visualisierung von Echtzeitdaten (rviz, rqt).  
- ğŸ”§ **Hardware-Optimierung**: AusfÃ¼hrung auf ressourcenbeschrÃ¤nktem Jetson Nano mittels Docker und SWAP-Speicheroptimierung fÃ¼r rechenintensive ML-Inferenz.

## ğŸ“š Projektstruktur

```
jetbot/
â”‚
â”œâ”€â”€ deep_learning/              # YOLOv7, SSD, Datenverarbeitung & Training
â”œâ”€â”€ apriltag/                   # AprilTag-Setup, Kalibrierung, ROS-Integration
â”œâ”€â”€ path_planning/             # RRT-Algorithmen, Koordinatentransformation
â”œâ”€â”€ motor_control/             # Differenzialantrieb mit PID-Regelung
â”œâ”€â”€ scripts/                   # ROS-Nodes & Launch-Dateien
â””â”€â”€ visualization/             # Karten, rviz-Konfiguration, Koordinatenprotokolle
```

## ğŸ“ˆ Visuelle Demonstration

### Objekterkennung (YOLOv3)  
![YOLO Object Detection]![image](https://github.com/user-attachments/assets/67f3d23c-4762-4822-a489-80e233cc2c36)

### Pfadplanung mit RRT  
![image](https://github.com/user-attachments/assets/cde0e555-9621-4ee4-8148-f3ca9b65fe1f)

### AprilTag-Lokalisierungsablauf  
![image](https://github.com/user-attachments/assets/aff197d6-ce69-448d-9e1d-6737363f098d)

### Voraussetzungen
- Jetson Nano mit Kameramodul  
- Ubuntu 20.04 + ROS Noetic  
- Python 3.8, PyTorch, OpenCV  
- Docker (fÃ¼r effizientes Training)

## ğŸ§ª Aufgaben & Ergebnisse

| Aufgabe | Beschreibung |
|--------|--------------|
| Aufgabe 1 | Objekterkennung und Erstellung einer 2D-Karte mit YOLO und AprilTags |
| Aufgabe 2 | Navigation um rote (im Uhrzeigersinn) und blaue (gegen den Uhrzeigersinn) WÃ¼rfel, Hindernisvermeidung |
| Aufgabe 3 | WÃ¼rfel in farblich passende Zielzonen schieben und zur Ausgangsposition zurÃ¼ckkehren |

> ğŸ Erreichte < 8 cm Fehler bei der Objektlokalisierung und ~2 s Latenz bei der Bildinferenz.

## ğŸ§  Technische Highlights

- ğŸ¤– **YOLOv3/YOLOv7** mit Roboflow-Vorverarbeitung  
- ğŸ§® **Perspektivtransformation** zur 3D-Lokalisierung aus 2D-Bilddaten  
- ğŸ“ **Kamerakalibrierung** mit ROS-Tools und Schachbrettmuster  
- ğŸ§­ **Proportionalregelung** fÃ¼r sanfte Navigation  
- ğŸ”„ **TF-Tree & Koordinatentransformationen** mit ROS  

## ğŸ›  Verwendete Technologien

![Python](https://img.shields.io/badge/Python-3.8-blue)  
![ROS](https://img.shields.io/badge/ROS-Noetic-blue)  
![Jetson Nano](https://img.shields.io/badge/Platform-JetsonNano-green)  
![YOLO](https://img.shields.io/badge/DeepLearning-YOLOv7-brightgreen)  
![RRT](https://img.shields.io/badge/Algorithm-RRT%20%2B%20RRT*-orange)  

## ğŸ‘¨â€ğŸ’» Mitwirkende

- **Husam Hamu** â€“ M.Sc. Mechatronik, TU Darmstadt  

[ğŸ“„ VollstÃ¤ndiger Projektbericht (PDF)](./docs/JetBot_Project_Report.pdf) <!-- Pfad ergÃ¤nzen, falls hochgeladen -->

## ğŸ“œ Lizenz

Dieses Projekt steht unter der MIT-Lizenz â€“ siehe die Datei [LICENSE](LICENSE) fÃ¼r Details.

---

Wenn du magst, kann ich dir das auch als formatiertes PDF oder Markdown-Datei exportieren. Sag einfach Bescheid!
